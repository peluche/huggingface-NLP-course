{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bad813e3-69ce-45e8-b4ee-dfd6eec7873f",
   "metadata": {},
   "source": [
    "# Huggingface - NLP Crourse - Chapter 1\n",
    "\n",
    "I'll be following along with: https://huggingface.co/learn/nlp-course/chapter1/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8c1e08-9ad0-4c20-8e00-83d8cd14bf5c",
   "metadata": {},
   "source": [
    "## Demo of `pipeline()` capabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac46acd3-a7ea-4608-843e-d177d6031533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# requirements\n",
    "# ---\n",
    "# !pip install transformers[sentencepiece]\n",
    "# !pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a740f6b3-b653-4b1f-9011-c92837ed057a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f271817c-7c6a-4838-9cb4-9545fc9680b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9598049521446228},\n",
       " {'label': 'NEGATIVE', 'score': 0.9994558691978455}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "classifier([\n",
    "  \"I've been waiting for a HuggingFace course my whole life.\",\n",
    "  \"I hate this so much!\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00fb0cbb-f1f0-4278-a1c8-fca492b0af0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/bart-large-mnli and revision c626438 (https://huggingface.co/facebook/bart-large-mnli).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sequence': 'This is a course about the Transformers library',\n",
       " 'labels': ['education', 'business', 'politics'],\n",
       " 'scores': [0.8445982336997986, 0.1119748130440712, 0.043426983058452606]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = pipeline(\"zero-shot-classification\")\n",
    "classifier(\n",
    "    \"This is a course about the Transformers library\",\n",
    "    candidate_labels=[\"education\", \"politics\", \"business\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "496c7886-37e1-43d6-80e9-16556558fedb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to gpt2 and revision 6c0e608 (https://huggingface.co/gpt2).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"In this course, we will teach you how to install, configure, configure, manage, and test WebSockets.\\n\\nDownload a Free WebSockets Console (Version 1.2 or later) which you can find in our site's download\"}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator = pipeline(\"text-generation\")\n",
    "generator(\"In this course, we will teach you how to\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c5a5e0a-868c-422f-9d0d-3c337eb1f2ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'In this course, we will teach you how to read, write, and write code. Each book will come with the following resources, and each page'},\n",
       " {'generated_text': 'In this course, we will teach you how to identify and manage risk behaviors.\\n\\n\\nThe best way to avoid making these mistakes is based on'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator = pipeline(\"text-generation\", model=\"distilgpt2\")\n",
    "generator(\n",
    "    \"In this course, we will teach you how to\",\n",
    "    max_length=30,\n",
    "    num_return_sequences=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18e184e6-8b7a-44e5-accd-e2eb095130fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilroberta-base and revision ec58a5b (https://huggingface.co/distilroberta-base).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'score': 0.1961977779865265,\n",
       "  'token': 30412,\n",
       "  'token_str': ' mathematical',\n",
       "  'sequence': 'This course will teach you all about mathematical models.'},\n",
       " {'score': 0.0405273362994194,\n",
       "  'token': 38163,\n",
       "  'token_str': ' computational',\n",
       "  'sequence': 'This course will teach you all about computational models.'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmasker = pipeline(\"fill-mask\")\n",
    "unmasker(\"This course will teach you all about <mask> models.\", top_k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2aaa94fe-ad62-45f4-953f-aec916266d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "C:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\transformers\\pipelines\\token_classification.py:169: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"AggregationStrategy.SIMPLE\"` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'PER',\n",
       "  'score': 0.9981694,\n",
       "  'word': 'Sylvain',\n",
       "  'start': 11,\n",
       "  'end': 18},\n",
       " {'entity_group': 'ORG',\n",
       "  'score': 0.9796019,\n",
       "  'word': 'Hugging Face',\n",
       "  'start': 33,\n",
       "  'end': 45},\n",
       " {'entity_group': 'LOC',\n",
       "  'score': 0.9932106,\n",
       "  'word': 'Brooklyn',\n",
       "  'start': 49,\n",
       "  'end': 57}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner = pipeline(\"ner\", grouped_entities=True)\n",
    "ner(\"My name is Sylvain and I work at Hugging Face in Brooklyn.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0677841e-1b1f-40fd-bbd5-9863998517ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 0.6949770450592041, 'start': 33, 'end': 45, 'answer': 'Hugging Face'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_answerer = pipeline(\"question-answering\")\n",
    "question_answerer(\n",
    "    question=\"Where do I work?\",\n",
    "    context=\"My name is Sylvain and I work at Hugging Face in Brooklyn\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8dc08ed2-720f-44b4-a8c3-26cf2175c548",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'summary_text': ' America has changed dramatically during recent years . The number of engineering graduates in the U.S. has declined in traditional engineering disciplines such as mechanical, civil,    electrical, chemical, and aeronautical engineering . Rapidly developing economies such as China and India continue to encourage and advance the teaching of engineering .'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer = pipeline(\"summarization\")\n",
    "summarizer(\n",
    "    \"\"\"\n",
    "    America has changed dramatically during recent years. Not only has the number of \n",
    "    graduates in traditional engineering disciplines such as mechanical, civil, \n",
    "    electrical, chemical, and aeronautical engineering declined, but in most of \n",
    "    the premier American universities engineering curricula now concentrate on \n",
    "    and encourage largely the study of engineering science. As a result, there \n",
    "    are declining offerings in engineering subjects dealing with infrastructure, \n",
    "    the environment, and related issues, and greater concentration on high \n",
    "    technology subjects, largely supporting increasingly complex scientific \n",
    "    developments. While the latter is important, it should not be at the expense \n",
    "    of more traditional engineering.\n",
    "\n",
    "    Rapidly developing economies such as China and India, as well as other \n",
    "    industrial countries in Europe and Asia, continue to encourage and advance \n",
    "    the teaching of engineering. Both China and India, respectively, graduate \n",
    "    six and eight times as many traditional engineers as does the United States. \n",
    "    Other industrial countries at minimum maintain their output, while America \n",
    "    suffers an increasingly serious decline in the number of engineering graduates \n",
    "    and a lack of well-educated engineers.\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9fd924e8-54f4-47b9-8f68-c0b2146b515f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\transformers\\models\\marian\\tokenization_marian.py:194: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'translation_text': 'This course is produced by Hugging Face.'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-fr-en\")\n",
    "translator(\"Ce cours est produit par Hugging Face.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24630b6-a2f2-4a54-882b-626d961222b5",
   "metadata": {},
   "source": [
    "## Bias and limitations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d656737-f931-447d-9d2d-4a01118450d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'cls.seq_relationship.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['carpenter', 'lawyer', 'farmer', 'businessman', 'doctor']\n",
      "['nurse', 'maid', 'teacher', 'waitress', 'prostitute']\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "unmasker = pipeline(\"fill-mask\", model=\"bert-base-uncased\")\n",
    "result = unmasker(\"This man works as a [MASK].\")\n",
    "print([r[\"token_str\"] for r in result])\n",
    "\n",
    "result = unmasker(\"This woman works as a [MASK].\")\n",
    "print([r[\"token_str\"] for r in result])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ddcd1e4-888b-41a0-896d-cbe829b1d430",
   "metadata": {},
   "source": [
    "# Huggingface - NLP Crourse - Chapter 2\n",
    "I'll be following along with: https://huggingface.co/learn/nlp-course/chapter2/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fcacff8-6e68-4a39-b01c-4ce2574940e2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Re-creating the `pipeline()`\n",
    "We are going to replicate the functionality of this `pipeline()` step by step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "afe6966b-ca61-4985-974f-65a1cf3a8a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9598049521446228},\n",
       " {'label': 'NEGATIVE', 'score': 0.9994558691978455}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "classifier(\n",
    "    [\n",
    "        \"I've been waiting for a HuggingFace course my whole life.\",\n",
    "        \"I hate this so much!\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a946538a-3267-44e4-bc9a-1053df204cf2",
   "metadata": {},
   "source": [
    "### 1- Tokenizer\n",
    "`pipeline()` pre-process the inputs into tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6553044-e121-442f-b81c-aad8387050bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c9ea5c3-c717-43fd-8512-97711260979f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  101,  1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172,\n",
      "          2607,  2026,  2878,  2166,  1012,   102],\n",
      "        [  101,  1045,  5223,  2023,  2061,  2172,   999,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]])}\n"
     ]
    }
   ],
   "source": [
    "raw_inputs = [\n",
    "    \"I've been waiting for a HuggingFace course my whole life.\",\n",
    "    \"I hate this so much!\",\n",
    "]\n",
    "inputs = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0725f065-b476-4c87-9a62-8709cbf46301",
   "metadata": {},
   "source": [
    "### 2- Model\n",
    "The tokens are passed to a pre-trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9043d28b-2909-4192-9f1f-b595bab7289d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel\n",
    "\n",
    "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "model = AutoModel.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b7e68517-276c-40ca-866d-037b920f6496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 16, 768])\n"
     ]
    }
   ],
   "source": [
    "outputs = model(**inputs)\n",
    "print(outputs.last_hidden_state.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd179a86-493f-4983-a72b-7e9ba3919a15",
   "metadata": {},
   "source": [
    "It produces a tensor `torch.Size([2, 16, 768])` or `batch_size = 2`, `sequence_length = 16`, and `hidden_size = 768` because the `AutoModel` doesn't include the head of the model.\n",
    "\n",
    "To have the output of the head we use `AutoModelForSequenceClassification` instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "15cd0093-5f91-4217-806e-c3b32c677617",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
    "outputs = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fafc370a-caf2-440f-b595-d808d00c5b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.5607,  1.6123],\n",
      "        [ 4.1692, -3.3464]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(outputs.logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6732d817-18dd-453e-b0cb-c56ce2c81649",
   "metadata": {},
   "source": [
    "The output tensor of size [2, 2] is not yet probabilities (they do not sum to 1), because the model returns logits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eccc2c34-5b90-461b-af6f-87ed6ab2067f",
   "metadata": {},
   "source": [
    "### 3- Postprocessing\n",
    "Apply `softmax()` to logits to normalize the probabilities to 1 and retrieve the labels in `model.config.id2label`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "52af8b9d-6d83-4180-bbae-2b52c4a8e779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.0195e-02, 9.5980e-01],\n",
      "        [9.9946e-01, 5.4418e-04]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "43142a2e-0b25-4456-a55a-ee79aed895c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'NEGATIVE', 1: 'POSITIVE'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d3087c56-41aa-4e13-ab2c-43a8ecde3cf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['NEGATIVE : 4.02%', 'POSITIVE : 95.98%'],\n",
       " ['NEGATIVE : 99.95%', 'POSITIVE : 0.05%']]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[f'{model.config.id2label[i]} : {pred:.2%}' for i, pred in enumerate(prediction)] for prediction in predictions]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c692c5-338b-4e66-b6a7-e22e0d4c3940",
   "metadata": {},
   "source": [
    "## Model and a checkpoint\n",
    "Instantiating a model with no checkpoint makes a model with random weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "016b7ec8-e20c-4290-a5c4-97228e5fae15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertConfig, BertModel\n",
    "\n",
    "# Building the config\n",
    "config = BertConfig()\n",
    "\n",
    "# Building the model from the config\n",
    "model = BertModel(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "411a2e98-18c0-41c0-b020-b2eaa1f89413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.32.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6857774-dc0c-4d0a-b7fc-32d181639572",
   "metadata": {},
   "source": [
    "Let's load a pre-trained model from a checkpoint instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "72aa557e-b39f-4a6b-967b-b3bcff678465",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel\n",
    "\n",
    "model = BertModel.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a62c61-c5d8-4f08-a369-b8eaf26d99c9",
   "metadata": {},
   "source": [
    "Models can be saved to disk using `.save_pretrained()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d1ac51d0-c44a-403a-8fea-a3ae7f0c934e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"directory_on_my_computer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6970ac13-f144-4113-80c6-1cd94855f6d3",
   "metadata": {},
   "source": [
    "## Tokenizer\n",
    "Models can only work with number, so inputs are converted to numbers before being fed to the model. The 3 main tokenization algorithms are:\n",
    "- Word based\n",
    "- Character based\n",
    "- Subword based"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc9e732-af9d-42fc-86eb-56ec34d007fd",
   "metadata": {},
   "source": [
    "### Word based tokenization\n",
    "Split text into words (by splitting on whitespace) and words are then converted to a unique id.\n",
    "\n",
    "e.g.: `'I like turtle'` -> `['I', 'like', 'turtle']` -> `[17, 494, 237]`\n",
    "\n",
    "Each word carry a lot of context and semantic meaning, but it has limitations, `dog` is almost like `dogs` but they will be treated completely differently. We also need an id for each word in the vocabulary which create a very large mapping and makes models bloated. Every new word will be treated as `out_of_vocabulary` which will also lead to a loss of information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c826a099-96b4-4324-9d08-84a0c2d880d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'like', 'turtle']\n",
      "[17, 494, 237]\n"
     ]
    }
   ],
   "source": [
    "vocabulary = {\n",
    "  '[OUT OF VOCABULARY]': 0,\n",
    "  'I': 17,\n",
    "  'turtle': 237,\n",
    "  'like': 494,\n",
    "}\n",
    "text = 'I like turtle'\n",
    "tokens = text.split()\n",
    "print(tokens)\n",
    "numerical_tokens = [vocabulary.get(t, 0) for t in tokens]\n",
    "print(numerical_tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e53d93-3d0d-4f64-a8b3-cda40f67e70d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Character based tokenization\n",
    "Split text into characters.\n",
    "\n",
    "e.g.: `'I like turtle'` -> `['I', ' ', 'l', 'i', 'k', 'e', ' ', 't', 'u', 'r', 't', 'l', 'e']` -> `[73, 32, 108, 105, 107, 101, 32, 116, 117, 114, 116, 108, 101]`\n",
    "\n",
    "The vocabulary is much smaller and cover the entire possible words spelled in your charset. But each token has a weaker meaning and hold less information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "119bd3f6-6941-45bf-842b-fb82e1f584e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', ' ', 'l', 'i', 'k', 'e', ' ', 't', 'u', 'r', 't', 'l', 'e']\n",
      "[73, 32, 108, 105, 107, 101, 32, 116, 117, 114, 116, 108, 101]\n"
     ]
    }
   ],
   "source": [
    "vocabulary = {c: i for i, c in enumerate([chr(n) for n in range(255)])}\n",
    "text = 'I like turtle'\n",
    "tokens = list(text)\n",
    "print(tokens)\n",
    "numerical_tokens = [vocabulary.get(t, 0) for t in tokens]\n",
    "print(numerical_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58018189-533d-4933-8f03-3e08f6f25152",
   "metadata": {},
   "source": [
    "## Subword based tokenization\n",
    "It's a compromise between word and char tokenizer.\n",
    "\n",
    "Frequent words are not split, while rare words are decomposed into meaningful subwords.\n",
    "\n",
    "e.g.:\n",
    "- `dog` -> `dog\\w`\n",
    "- `dogs` -> [`dog`, `s\\w`]\n",
    "- `tokenization` -> [`token`, `##ization`]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3b57b797-138e-4354-bbf3-9b0c06362bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f24c90e7-5c72-4baf-a38a-130286a07b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "12104d3d-d44d-477d-85b1-ee5cd6b47c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Using', 'a', 'Trans', '##former', 'network', 'is', 'simple']\n",
      "[7993, 170, 13809, 23763, 2443, 1110, 3014]\n",
      "Using a transformer network is simple\n"
     ]
    }
   ],
   "source": [
    "sequence = \"Using a Transformer network is simple\"\n",
    "\n",
    "# tokenize step by step\n",
    "tokens = tokenizer.tokenize(sequence)\n",
    "print(tokens)\n",
    "ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "print(ids)\n",
    "\n",
    "# or use the equivalent\n",
    "tokenizer(sequence)\n",
    "\n",
    "# decoding\n",
    "decoded_string = tokenizer.decode([7993, 170, 11303, 1200, 2443, 1110, 3014])\n",
    "print(decoded_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3443897-06cd-46e2-8972-ae185e34cf49",
   "metadata": {},
   "source": [
    "## Tokenizing multiple inputs at once\n",
    "When tokenizing multiple inputs we have to make sure they are the same size as tensors need to have regular dimensions. So the inputs are padded up to a certain size. To match that we pass a mask for the attention layer so the padding tokens are ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "70657951-e3d1-4adc-afa9-9fffe0c91d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs: tensor([[ 1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172,  2607,\n",
      "          2026,  2878,  2166,  1012]])\n",
      "Logits: tensor([[-2.7276,  2.8789]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
    "\n",
    "sequence = \"I've been waiting for a HuggingFace course my whole life.\"\n",
    "\n",
    "tokens = tokenizer.tokenize(sequence)\n",
    "ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "input_ids = torch.tensor([ids])\n",
    "print(\"Input IDs:\", input_ids)\n",
    "\n",
    "output = model(input_ids)\n",
    "print(\"Logits:\", output.logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3443c26-6add-4907-ab6b-21ad69b94108",
   "metadata": {},
   "source": [
    "For batched requests we need to pad the inputs to be the same size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "87ac0dfb-a901-4286-ad75-e1fe9c648564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.5694, -1.3895],\n",
      "        [ 0.5803, -0.4125]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "batched_ids = [\n",
    "    [200, 200, 200],\n",
    "    [200, 200, tokenizer.pad_token_id],\n",
    "]\n",
    "\n",
    "attention_mask = [\n",
    "    [1, 1, 1],\n",
    "    [1, 1, 0],\n",
    "]\n",
    "\n",
    "outputs = model(torch.tensor(batched_ids), attention_mask=torch.tensor(attention_mask))\n",
    "print(outputs.logits)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_hf_nlp",
   "language": "python",
   "name": "venv_hf_nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
